{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilingual NER Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from nltk.corpus.reader.conll import ConllCorpusReader\n",
    "import re\n",
    "from math import floor\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Bidirectional, Flatten, Dropout, TimeDistributed\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "from keras_contrib.layers import CRF\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data from File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_en_train = np.load('data/eng.X.train.npy', mmap_mode='r')\n",
    "y_en_train_label = np.load('data/eng.y.train.npy', mmap_mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_en_test = np.load('data/eng.X.testa.npy', mmap_mode='r')\n",
    "y_en_test_label = np.load('data/eng.y.testa.npy', mmap_mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_de_test = np.load('data/deu.X.testa.npy', mmap_mode='r')\n",
    "y_de_test_label = np.load('data/deu.y.testa.npy', mmap_mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_de_train = np.load('data/deu.X.train.npy', mmap_mode='r')\n",
    "y_de_train_label = np.load('data/deu.y.train.npy', mmap_mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_es_test = np.load('data/esp.X.testa.npy', mmap_mode='r')\n",
    "y_es_test_label = np.load('data/esp.y.testa.npy', mmap_mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_es_train = np.load('data/esp.X.train.npy', mmap_mode='r')\n",
    "y_es_train_label = np.load('data/esp.y.train.npy', mmap_mode='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['B-MISC', 'I-MISC', 'I-LOC', 'B-PER', 'I-PER', 'B-LOC', 'I-ORG', 'B-ORG', 'O']\n",
      "Missing in English training: set() {'B-PER'} {'B-PER'}\n",
      "Missing in German training: set() {'B-PER'} {'B-PER'}\n",
      "Missing in Spanish training: set() set() set()\n"
     ]
    }
   ],
   "source": [
    "train_en_classes = set()\n",
    "for sent in y_en_train_label:\n",
    "    for label in sent:\n",
    "        train_en_classes.add(label)\n",
    "        \n",
    "test_en_classes = set()\n",
    "for sent in y_en_test_label:\n",
    "    for label in sent:\n",
    "        test_en_classes.add(label)\n",
    "        \n",
    "train_de_classes = set()\n",
    "for sent in y_de_train_label:\n",
    "    for label in sent:\n",
    "        train_de_classes.add(label)\n",
    "        \n",
    "test_de_classes = set()\n",
    "for sent in y_de_test_label:\n",
    "    for label in sent:\n",
    "        test_de_classes.add(label)\n",
    "        \n",
    "train_es_classes = set()\n",
    "for sent in y_es_train_label:\n",
    "    for label in sent:\n",
    "        train_es_classes.add(label)\n",
    "        \n",
    "test_es_classes = set()\n",
    "for sent in y_es_test_label:\n",
    "    for label in sent:\n",
    "        test_es_classes.add(label)\n",
    "\n",
    "classes = list(train_en_classes.union(test_en_classes.union(train_de_classes.union(test_de_classes.union(train_es_classes.union(test_es_classes))))))\n",
    "print(\"Classes:\", classes)\n",
    "print(\"Missing in English training:\", \n",
    "      test_en_classes.difference(train_en_classes),\n",
    "      test_de_classes.difference(train_en_classes), \n",
    "      test_es_classes.difference(train_en_classes))\n",
    "print(\"Missing in German training:\", \n",
    "      test_en_classes.difference(train_de_classes),\n",
    "      test_de_classes.difference(train_de_classes), \n",
    "      test_es_classes.difference(train_de_classes))\n",
    "\n",
    "print(\"Missing in Spanish training:\", \n",
    "      test_en_classes.difference(train_es_classes),\n",
    "      test_de_classes.difference(train_es_classes), \n",
    "      test_es_classes.difference(train_es_classes))\n",
    "\n",
    "num_classes = len(classes)\n",
    "encoded_classes = range(num_classes)\n",
    "class2idx = {classes[enc]: enc for enc in encoded_classes}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Binary Variation of the Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lab2bin(y_labels):\n",
    "    y_bin = np.copy(y_labels)\n",
    "    for i in range(len(y_bin)):\n",
    "        for j in range(len(y_bin[i])):\n",
    "            if y_bin[i][j] != 'O':\n",
    "                if y_bin[i][j][0] == 'B':\n",
    "                    y_bin[i][j] = 'B-NE'\n",
    "                else:\n",
    "                    y_bin[i][j] = 'I-NE'\n",
    "    return y_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_en_train_bin_label = lab2bin(y_en_train_label)              \n",
    "y_en_test_bin_label = lab2bin(y_en_test_label)\n",
    " \n",
    "y_de_train_bin_label = lab2bin(y_de_train_label)\n",
    "y_de_test_bin_label = lab2bin(y_de_test_label)\n",
    "\n",
    "y_es_train_bin_label = lab2bin(y_es_train_label)\n",
    "y_es_test_bin_label = lab2bin(y_es_test_label)\n",
    "\n",
    "\n",
    "bin_classes = ['O', 'B-NE', 'I-NE']\n",
    "bin_num_classes = len(bin_classes)\n",
    "bin_encoded_classes = range(bin_num_classes)\n",
    "binclass2idx = {bin_classes[enc]: enc for enc in bin_encoded_classes}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the Labels to Categorical Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_en_train = np.array([np.array(to_categorical([class2idx[cls] for cls in sent], num_classes=num_classes)) for sent in y_en_train_label])\n",
    "y_en_test = np.array([np.array(to_categorical([class2idx[cls] for cls in sent], num_classes=num_classes)) for sent in y_en_test_label])\n",
    "y_de_train = np.array([np.array(to_categorical([class2idx[cls] for cls in sent], num_classes=num_classes)) for sent in y_de_train_label])\n",
    "y_de_test = np.array([np.array(to_categorical([class2idx[cls] for cls in sent], num_classes=num_classes)) for sent in y_de_test_label])\n",
    "y_es_train = np.array([np.array(to_categorical([class2idx[cls] for cls in sent], num_classes=num_classes)) for sent in y_es_train_label])\n",
    "y_es_test = np.array([np.array(to_categorical([class2idx[cls] for cls in sent], num_classes=num_classes)) for sent in y_es_test_label])\n",
    "\n",
    "y_en_train_bin = np.array([np.array(to_categorical([binclass2idx[cls] for cls in sent], num_classes=bin_num_classes)) for sent in y_en_train_bin_label])\n",
    "y_en_test_bin = np.array([np.array(to_categorical([binclass2idx[cls] for cls in sent], num_classes=bin_num_classes)) for sent in y_en_test_bin_label])\n",
    "y_de_train_bin = np.array([np.array(to_categorical([binclass2idx[cls] for cls in sent], num_classes=bin_num_classes)) for sent in y_de_train_bin_label])\n",
    "y_de_test_bin = np.array([np.array(to_categorical([binclass2idx[cls] for cls in sent], num_classes=bin_num_classes)) for sent in y_de_test_bin_label])\n",
    "y_es_train_bin = np.array([np.array(to_categorical([binclass2idx[cls] for cls in sent], num_classes=bin_num_classes)) for sent in y_es_train_bin_label])\n",
    "y_es_test_bin = np.array([np.array(to_categorical([binclass2idx[cls] for cls in sent], num_classes=bin_num_classes)) for sent in y_es_test_bin_label])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the Languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.vstack([X_en_train, X_de_train, X_es_train])\n",
    "y_train = np.vstack([y_en_train, y_de_train, y_es_train])\n",
    "y_train_bin = np.vstack([y_en_train_bin, y_de_train_bin, y_es_train_bin])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = 0.1\n",
    "recurrent_dropout = 0.3\n",
    "window_size = X_en_train[0].shape[0]\n",
    "num_features = X_en_train[0].shape[1]\n",
    "hidden_nodes = 100\n",
    "\n",
    "def create_model(num_classes, num_features, hidden_nodes=100):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(\n",
    "        LSTM(units=num_features, return_sequences=True, dropout=dropout, recurrent_dropout=recurrent_dropout),\n",
    "        input_shape=(window_size, num_features,),\n",
    "        merge_mode='concat'))\n",
    "#     model.add(Dropout(dropout))\n",
    "#     model.add(BatchNormalization())\n",
    "    model.add(TimeDistributed(Dense(hidden_nodes, activation='relu')))\n",
    "    # add a CRF layer to enforce NER IOB rules\n",
    "    crf = CRF(num_classes, sparse_target=False)\n",
    "    model.add(crf)\n",
    "    print(\"Summary:\", model.summary())\n",
    "    model.compile(optimizer='rmsprop', loss=crf.loss_function, metrics=[crf.accuracy])\n",
    "#     model.add(Dense(num_classes, activation='softmax'))\n",
    "#     model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (11376, 70, 300)\n",
      "y shape: (11376, 70, 9)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 70, 600)           1442400   \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 70, 100)           60100     \n",
      "_________________________________________________________________\n",
      "crf_1 (CRF)                  (None, 70, 9)             1008      \n",
      "=================================================================\n",
      "Total params: 1,503,508\n",
      "Trainable params: 1,503,508\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Summary: None\n",
      "Epoch 1/3\n",
      "10200/11376 [=========================>....] - ETA: 1:01 - loss: 0.1534 - acc: 0.9595"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-22e6ae121f23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_en_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_en_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_en_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1220\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                             \u001b[0;31m# Do not slice the training phase flag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1222\u001b[0;31m                             \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1223\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m                             \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_slice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/numpy/core/memmap.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mmemmap\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mmap\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/numpy/core/memmap.py\u001b[0m in \u001b[0;36m__array_finalize__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__array_finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_mmap'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmay_share_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mmap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"X shape:\", X_en_train.shape)\n",
    "print(\"y shape:\", y_en_train.shape)\n",
    "model = create_model(num_classes, num_features)\n",
    "model.fit(X_en_train, y_en_train, batch_size=50, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/eng_train.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arr2label(cats, labels):\n",
    "    new_labels = []\n",
    "    for i in range(len(cats)):\n",
    "        sent_labels = []\n",
    "        for j in range(len(cats[i])):\n",
    "            label = np.argmax(cats[i][j])\n",
    "            label = labels[label]\n",
    "            new_labels.append(label)\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English Results from English Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_en = model.predict(X_en_test)\n",
    "score_en = model.evaluate(X_en_test, y_en_test)\n",
    "for i in range(len(score_en)):\n",
    "    print(str(model.metrics_names[i]) + ': ' + str(score_en[i]))\n",
    "y_pred_en_label = arr2label(y_pred_en, classes)\n",
    "y_true_en_label = arr2label(y_en_test, classes)\n",
    "\n",
    "precision = precision_score(y_true_en_label, y_pred_en_label, average='macro')\n",
    "recall = recall_score(y_true_en_label, y_pred_en_label, average='macro')\n",
    "f1 = f1_score(y_true_en_label, y_pred_en_label, average='macro')\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1:\", f1)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_true_en_label, y_pred_en_label, labels=classes)\n",
    "plot_confusion_matrix(cnf_matrix, classes=classes, normalize=True,\n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### German Results from English Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_de = model.predict(X_de_test)\n",
    "score_de = model.evaluate(X_de_test, y_de_test)\n",
    "for i in range(len(score_de)):\n",
    "    print(str(model.metrics_names[i]) + ': ' + str(score_de[i]))\n",
    "y_pred_de_label = arr2label(y_pred_de, classes)\n",
    "y_true_de_label = arr2label(y_de_test, classes)\n",
    "\n",
    "precision = precision_score(y_true_de_label, y_pred_de_label, average='macro')\n",
    "recall = recall_score(y_true_de_label, y_pred_de_label, average='macro')\n",
    "f1 = f1_score(y_true_de_label, y_pred_de_label, average='macro')\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1:\", f1)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_true_de_label, y_pred_de_label, labels=classes)\n",
    "plot_confusion_matrix(cnf_matrix, classes=classes, normalize=True,\n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spanish Results from English Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_es = model.predict(X_es_test)\n",
    "score_es = model.evaluate(X_es_test, y_es_test)\n",
    "for i in range(len(score_es)):\n",
    "    print(str(model.metrics_names[i]) + ': ' + str(score_es[i]))\n",
    "y_pred_es_label = arr2label(y_pred_es, classes)\n",
    "y_true_es_label = arr2label(y_es_test, classes)\n",
    "\n",
    "precision = precision_score(y_true_es_label, y_pred_es_label, average='macro')\n",
    "recall = recall_score(y_true_es_label, y_pred_es_label, average='macro')\n",
    "f1 = f1_score(y_true_es_label, y_pred_es_label, average='macro')\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1:\", f1)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_true_es_label, y_pred_es_label, labels=classes)\n",
    "plot_confusion_matrix(cnf_matrix, classes=classes, normalize=True,\n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Binary Task on English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = create_model(bin_num_classes, num_features)\n",
    "model.fit(X_en_train, y_en_train_bin, batch_size=50, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/eng_train_bin.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary English Results from English Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_en = model.predict(X_en_test)\n",
    "score_en = model.evaluate(X_en_test, y_en_test_bin)\n",
    "for i in range(len(score_en)):\n",
    "    print(str(model.metrics_names[i]) + ': ' + str(score_en[i]))\n",
    "y_pred_en_label = arr2label(y_pred_en, bin_classes)\n",
    "y_true_en_label = arr2label(y_en_test_bin, bin_classes)\n",
    "\n",
    "precision = precision_score(y_true_en_label, y_pred_en_label, average='macro')\n",
    "recall = recall_score(y_true_en_label, y_pred_en_label, average='macro')\n",
    "f1 = f1_score(y_true_en_label, y_pred_en_label, average='macro')\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1:\", f1)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_true_en_label, y_pred_en_label, labels=bin_classes)\n",
    "plot_confusion_matrix(cnf_matrix, classes=bin_classes, normalize=True,\n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary German Results from English Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_de = model.predict(X_de_test)\n",
    "score_de = model.evaluate(X_de_test, y_de_test_bin)\n",
    "for i in range(len(score_de)):\n",
    "    print(str(model.metrics_names[i]) + ': ' + str(score_de[i]))\n",
    "y_pred_de_label = arr2label(y_pred_de, bin_classes)\n",
    "y_true_de_label = arr2label(y_de_test_bin, bin_classes)\n",
    "\n",
    "precision = precision_score(y_true_de_label, y_pred_de_label, average='macro')\n",
    "recall = recall_score(y_true_de_label, y_pred_de_label, average='macro')\n",
    "f1 = f1_score(y_true_de_label, y_pred_de_label, average='macro')\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1:\", f1)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_true_de_label, y_pred_de_label, labels=bin_classes)\n",
    "plot_confusion_matrix(cnf_matrix, classes=bin_classes, normalize=True,\n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Spanish Results from English Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_es = model.predict(X_es_test)\n",
    "score_es = model.evaluate(X_es_test, y_es_test_bin)\n",
    "for i in range(len(score_es)):\n",
    "    print(str(model.metrics_names[i]) + ': ' + str(score_es[i]))\n",
    "y_pred_es_label = arr2label(y_pred_es, bin_classes)\n",
    "y_true_es_label = arr2label(y_es_test_bin, bin_classes)\n",
    "\n",
    "precision = precision_score(y_true_es_label, y_pred_es_label, average='macro')\n",
    "recall = recall_score(y_true_es_label, y_pred_es_label, average='macro')\n",
    "f1 = f1_score(y_true_es_label, y_pred_es_label, average='macro')\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1:\", f1)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_true_es_label, y_pred_es_label, labels=bin_classes)\n",
    "plot_confusion_matrix(cnf_matrix, classes=bin_classes, normalize=True,\n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on Every Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (29407, 70, 300)\n",
      "y shape: (29407, 70, 9)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_2 (Bidirection (None, 70, 600)           1442400   \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 70, 100)           60100     \n",
      "_________________________________________________________________\n",
      "crf_2 (CRF)                  (None, 70, 9)             1008      \n",
      "=================================================================\n",
      "Total params: 1,503,508\n",
      "Trainable params: 1,503,508\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Summary: None\n",
      "Epoch 1/3\n",
      "28950/29407 [============================>.] - ETA: 9s - loss: 0.1364 - acc: 0.9647 "
     ]
    }
   ],
   "source": [
    "print(\"X shape:\", X_train.shape)\n",
    "print(\"y shape:\", y_train.shape)\n",
    "model = create_model(num_classes, num_features)\n",
    "model.fit(X_train, y_train, batch_size=50, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/full_train.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English Results from Full Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_en = model.predict(X_en_test)\n",
    "score_en = model.evaluate(X_en_test, y_en_test)\n",
    "for i in range(len(score_en)):\n",
    "    print(str(model.metrics_names[i]) + ': ' + str(score_en[i]))\n",
    "y_pred_en_label = arr2label(y_pred_en, classes)\n",
    "y_true_en_label = arr2label(y_en_test, classes)\n",
    "\n",
    "precision = precision_score(y_true_en_label, y_pred_en_label, average='macro')\n",
    "recall = recall_score(y_true_en_label, y_pred_en_label, average='macro')\n",
    "f1 = f1_score(y_true_en_label, y_pred_en_label, average='macro')\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1:\", f1)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_true_en_label, y_pred_en_label, labels=classes)\n",
    "plot_confusion_matrix(cnf_matrix, classes=classes, normalize=True,\n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### German Results from Full Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_de = model.predict(X_de_test)\n",
    "score_de = model.evaluate(X_de_test, y_de_test)\n",
    "for i in range(len(score_de)):\n",
    "    print(str(model.metrics_names[i]) + ': ' + str(score_de[i]))\n",
    "y_pred_de_label = arr2label(y_pred_de, classes)\n",
    "y_true_de_label = arr2label(y_de_test, classes)\n",
    "\n",
    "precision = precision_score(y_true_de_label, y_pred_de_label, average='macro')\n",
    "recall = recall_score(y_true_de_label, y_pred_de_label, average='macro')\n",
    "f1 = f1_score(y_true_de_label, y_pred_de_label, average='macro')\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1:\", f1)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_true_de_label, y_pred_de_label, labels=classes)\n",
    "plot_confusion_matrix(cnf_matrix, classes=classes, normalize=True,\n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spanish Results from Full Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_es = model.predict(X_es_test)\n",
    "score_es = model.evaluate(X_es_test, y_es_test)\n",
    "for i in range(len(score_es)):\n",
    "    print(str(model.metrics_names[i]) + ': ' + str(score_es[i]))\n",
    "y_pred_es_label = arr2label(y_pred_es, classes)\n",
    "y_true_es_label = arr2label(y_es_test, classes)\n",
    "\n",
    "precision = precision_score(y_true_es_label, y_pred_es_label, average='macro')\n",
    "recall = recall_score(y_true_es_label, y_pred_es_label, average='macro')\n",
    "f1 = f1_score(y_true_es_label, y_pred_es_label, average='macro')\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1:\", f1)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_true_es_label, y_pred_es_label, labels=classes)\n",
    "plot_confusion_matrix(cnf_matrix, classes=classes, normalize=True,\n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Task with Full Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"X shape:\", X_train.shape)\n",
    "print(\"y shape:\", y_train_bin.shape)\n",
    "model = create_model(bin_num_classes, num_features)\n",
    "model.fit(X_train, y_train_bin, batch_size=50, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/full_train_bin.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary English Results from Full Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_en = model.predict(X_en_test)\n",
    "score_en = model.evaluate(X_en_test, y_en_test_bin)\n",
    "for i in range(len(score_en)):\n",
    "    print(str(model.metrics_names[i]) + ': ' + str(score_en[i]))\n",
    "y_pred_en_label = arr2label(y_pred_en, bin_classes)\n",
    "y_true_en_label = arr2label(y_en_test_bin, bin_classes)\n",
    "\n",
    "precision = precision_score(y_true_en_label, y_pred_en_label, average='macro')\n",
    "recall = recall_score(y_true_en_label, y_pred_en_label, average='macro')\n",
    "f1 = f1_score(y_true_en_label, y_pred_en_label, average='macro')\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1:\", f1)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_true_en_label, y_pred_en_label, labels=bin_classes)\n",
    "plot_confusion_matrix(cnf_matrix, classes=bin_classes, normalize=True,\n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary German Results from Full Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_de = model.predict(X_de_test)\n",
    "score_de = model.evaluate(X_de_test, y_de_test_bin)\n",
    "for i in range(len(score_de)):\n",
    "    print(str(model.metrics_names[i]) + ': ' + str(score_de[i]))\n",
    "y_pred_de_label = arr2label(y_pred_de, bin_classes)\n",
    "y_true_de_label = arr2label(y_de_test_bin, bin_classes)\n",
    "\n",
    "precision = precision_score(y_true_de_label, y_pred_de_label, average='macro')\n",
    "recall = recall_score(y_true_de_label, y_pred_de_label, average='macro')\n",
    "f1 = f1_score(y_true_de_label, y_pred_de_label, average='macro')\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1:\", f1)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_true_de_label, y_pred_de_label, labels=bin_classes)\n",
    "plot_confusion_matrix(cnf_matrix, classes=bin_classes, normalize=True,\n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Spanish Results from Full Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_es = model.predict(X_es_test)\n",
    "score_es = model.evaluate(X_es_test, y_es_test_bin)\n",
    "for i in range(len(score_es)):\n",
    "    print(str(model.metrics_names[i]) + ': ' + str(score_es[i]))\n",
    "y_pred_es_label = arr2label(y_pred_es, bin_classes)\n",
    "y_true_es_label = arr2label(y_es_test_bin, bin_classes)\n",
    "\n",
    "precision = precision_score(y_true_es_label, y_pred_es_label, average='macro')\n",
    "recall = recall_score(y_true_es_label, y_pred_es_label, average='macro')\n",
    "f1 = f1_score(y_true_es_label, y_pred_es_label, average='macro')\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1:\", f1)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_true_es_label, y_pred_es_label, labels=bin_classes)\n",
    "plot_confusion_matrix(cnf_matrix, classes=bin_classes, normalize=True,\n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
