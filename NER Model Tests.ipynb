{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from nltk.corpus.reader.conll import ConllCorpusReader\n",
    "import re\n",
    "from math import floor\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Bidirectional, Flatten, Dropout, TimeDistributed\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "from keras_contrib.layers import CRF\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 70\n",
    "num_featuers = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_padded_sentence_features(sentences, num_features, max_length, wv):\n",
    "    features = np.empty((0, max_length, num_features))\n",
    "    for i in range(len(sentences)):\n",
    "        if i % 100 == 0:\n",
    "            print(\"Processed\", i, \"of\", len(sentences))\n",
    "        sent = sentences[i]\n",
    "        new_sent = []\n",
    "        for j in range(max_length):\n",
    "            if 0 <= j < len(sent):\n",
    "                this_word = sent[j]\n",
    "                if this_word in wv.vocab:\n",
    "                    new_sent.append(wv.get_vector(this_word))\n",
    "                elif this_word == '':\n",
    "                    new_sent.append(np.zeros(num_features))\n",
    "                else:\n",
    "                    new_sent.append(np.random.uniform(-0.25,0.25, num_features))  # random vector for unknown\n",
    "            else:\n",
    "                new_sent.append(np.zeros(num_features))\n",
    "                sent_labels = np.append(sent_labels, 'O')\n",
    "\n",
    "        feature_stack = np.dstack([[new_sent]])\n",
    "        features = np.vstack([features, feature_stack])\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums_regex = re.compile(r'0+')\n",
    "def clean_sents(sents, max_length):\n",
    "    cleaned = []\n",
    "    # remove sentences shorter than 5 words\n",
    "    for sent in sents:\n",
    "        if len(sent) > 4 and len(sent) <= max_length:\n",
    "            new_sent = []\n",
    "            # clean the words\n",
    "            for word in sent:\n",
    "                this_word = word.lower()\n",
    "                new_word = ''\n",
    "                # replace numbers with 0\n",
    "                for char in this_word:\n",
    "                    if char.isalpha():\n",
    "                        new_word = new_word + char\n",
    "                    elif char.isdigit():\n",
    "                        new_word = new_word + '0'\n",
    "                new_word = nums_regex.sub('0', new_word)\n",
    "                new_sent.append((new_word, word[1], word[2]))\n",
    "            cleaned.append(new_sent)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arr2label(cats, labels):\n",
    "    new_labels = []\n",
    "    for i in range(len(cats)):\n",
    "        sent_labels = []\n",
    "        for j in range(len(cats[i])):\n",
    "            label = np.argmax(cats[i][j])\n",
    "            label = labels[label]\n",
    "            new_labels.append(label)\n",
    "    return new_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = KeyedVectors.load_word2vec_format('data/wiki.multi.en.vec.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_it = KeyedVectors.load_word2vec_format('data/wiki.multi.it.vec.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_en_train = np.load('data/eng.X.train.npy', mmap_mode='r')\n",
    "y_en_train_label = np.load('data/eng.y.train.npy', mmap_mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['B-MISC', 'I-MISC', 'I-LOC', 'B-PER', 'I-PER', 'B-LOC', 'I-ORG', 'B-ORG', 'O']\n",
    "encoded_classes = range(num_classes)\n",
    "class2idx = {classes[enc]: enc for enc in encoded_classes}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('models/full_train.h5', custom_objects={'CRF': CRF})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sent1 = 'The model that Steven and Tony created had never seen a sentence such as this!'\n",
    "test_sent2 = 'Sai la semplicità di Messer Nicia, che benché sia dottore, egli è el più semplice e il più sciocco uomo di Firenze'\n",
    "test_sent2_eng = 'You know the simplicity of Messer Nicia, that although he is a doctor, he is the simplest and the silliest man in Florence'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
